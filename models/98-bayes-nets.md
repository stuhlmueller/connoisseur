## Outline of different possible generative models

### Notation

There are fixed functions u, b and g. There's a sequence of context observations {x_i}. We also observe the outputs of these functions for each context observations. The training data is typically of form {(x_i, g(x_i), b(x_i))} and the test data of form {(x_i, b(x_i))}, with the goal to predict u(x_i). The variables are as follows: 

- x_i is the i-th observation of the context variable

- u is the utility function on the context x. We write u_i for u(x_i), i.e. the utility of the i-th context.

- b is a function that outputs the "biased" side-information. It's either a function of x_i or u(x_i). We write b_i for the i-th observation of biased side-information.

- g is a function that outputs the "gold-standard" side-information. It's either a function of x_i or u(x_i). We write g_i for the i-th observation of the gold-standard side-information.



## Model 1: Utility observed, biased side-info depends directly on utility
This is the simplest model of learning from side information. There is a utility function `u` and a "biased side-information" function `b`. In this case, `b` acts directly on `u(x)` (e.g. by adding noise) rather than on the context `x`. There is no "gold-standard" side-information. 

###Bayes net
Note: we use plate notation for the series of observations of x_i and functions of it. While u(x_i) depends on x_i, we will generally leave out the dependency since we won't infer anything about the marginal distribution P(x_i). 


###Concrete example:
x ~ N(0,1)
u(x) = a(x), where a ~ N(0,1)
b_i = b(u_i) = u_i + constant + e_b, where constant ~ N(0,1) and e_b ~ Gamma(1,1)

**Training**: (x_i, u(x_i), b(u(x_i)) )
**Test**: (x_i, b(u(x_i) ))  ->  u(x_i)

###Comments on P( u(x_i) | b_i, x_i, training):
How does b_i (the biased side-information for observation x_i) help predict u(x_i)? Suppose we are fairly uncertain about u(x_i) because x_i is outside the training data. We might have learned that b has low noise and low bias. And so u(x_i) is likely close to b_i. 

###Tractability
For exact inference, we'd be inferring both u and b. Inference over u might be hard. Inference over b (if we knew u) should be easy because it's a function from R to R and the number of data points N is small.


## Model 2: Utility observed, biased side-info is similar to utility function
If the biased side-info depends directly on the utility, then we can't represent side-info that always ignores a particular component of x_i. So in a more flexible generative model for side-information `b` acts on `x_i` directly rather than `u(x_i)`.

We need a prior on `u` and `b` that makes them dependent. This is generally done by parameterizing the functions and having them share some parameters. (One option is to have a single matrix or neural network from vector x to vector (u(x), b(x)) and to use a prior on parameters that tends to create similar functions for each of the outputs). 

### Bayes Net


### Concrete example
x ~ N(0,1)
u(x) = a(x), where a ~ N(0,1)
b_i = b(x_i) = (a+b)x + e, where b ~ N(0,1), e ~ Gamma(1,1)

**Training**: (x_i, u(x_i), b(x_i) )
**Test**: (x_i, b(x_i))  ->  u(x_i)

###Comments on P( u(x_i) | b_i, x_i, training):
How does b_i (the biased side-information for observation x_i) help predict u(x_i)? Important difference from Model 1. In this case, if we knew b exactly, then learning b(x_i) tell us nothing new. So the side-information would be worth nothing in this case. In Model 1, even if we knew the exact function from u(x_i) to b_i, it would still help us to learn b_i. In practice, to learn b

###Tractability


## Model 3: Utility not observed, gold-standard depends directly on utility, biased side-info is similar function to utility

- might be easier analytically to work with gold-standard in case where it's function of u(x). this is like label noise case that lawrence discusses and same trick of reversing arrows may work there. 

## Model 4: Utility not observed, all side-info is generated by functions similar to utility

## Model 5: Learn conditional distribution directly
Marginalize out some variables and reverse some arrows. You are learning 






